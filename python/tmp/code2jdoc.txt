02/26/2024 08:26:03 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name python --data_dir ../../data/ --model_dir ../../tmp --model_name code2jdoc --train_src train/code.original_subtoken --train_sub train/code.original_subtoken --train_ky train/code.intoken --train_it train/code.intoken --train_is train/code.instatement --train_df train/dataflow_subtoken_v3.npy --train_cf train/dataflow_subtoken_v3.npy --train_tgt train/javadoc.original --dev_src test/code.original_subtoken --dev_sub test/code.original_subtoken --dev_ky test/code.intoken --dev_it test/code.intoken --dev_is test/code.instatement --dev_df test/dataflow_subtoken_v3.npy --dev_cf test/dataflow_subtoken_v3.npy --dev_tgt test/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 50 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 0 --use_neg_dist True --nlayers 8 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True ]
02/26/2024 08:26:03 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:03 PM: [ Load and process data files ]
02/26/2024 08:26:11 PM: [ Num train examples = 55538 ]
02/26/2024 08:26:11 PM: [ Dataset weights = {1: 1.0} ]
02/26/2024 08:26:13 PM: [ Num dev examples = 18502 ]
02/26/2024 08:26:13 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:13 PM: [ Training model from scratch... ]
02/26/2024 08:26:13 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:13 PM: [ Build word dictionary ]
02/26/2024 08:26:17 PM: [ Num words in source = 50000 and target = 30000 ]
02/26/2024 08:26:19 PM: [ Trainable #parameters [encoder-decoder] 58.9M [total] 101M ]
02/26/2024 08:26:19 PM: [ Breakdown of the trainable paramters
+---------------------------------------------------------------+--------------+----------+
| Layer Name                                                    | Output Shape |  Param # |
+---------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight | [50000, 512] | 25600000 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight | [30000, 512] | 15360000 |
| embedder.tgt_pos_embeddings.weight                            |    [52, 512] |    26624 |
| encoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| generator.bias                                                |      [30000] |    30000 |
| copy_attn.linear_in.weight                                    |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                   |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                             |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                               |          [1] |        1 |
+---------------------------------------------------------------+--------------+----------+ ]
02/26/2024 08:26:19 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:19 PM: [ Make data loaders ]
02/26/2024 08:26:19 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:19 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": false,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "python"
    ],
    "dataset_weights": {
        "1": 1.0
    },
    "dev_cf": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_df": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_is": [
        "test/code.instatement"
    ],
    "dev_it": [
        "test/code.intoken"
    ],
    "dev_ky": [
        "test/code.intoken"
    ],
    "dev_src": [
        "test/code.original_subtoken"
    ],
    "dev_src_controlflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_dataflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_instatement_files": [
        "../../data/python/test/code.instatement"
    ],
    "dev_src_intoken_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_keyword_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_subtoken_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_sub": [
        "test/code.original_subtoken"
    ],
    "dev_tgt": [
        "test/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/python/test/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/code2jdoc.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        0
    ],
    "max_src_len": 150,
    "max_tgt_len": 50,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/code2jdoc.mdl",
    "model_name": "code2jdoc",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 8,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 55538,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/code2jdoc.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_cf": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_df": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_is": [
        "train/code.instatement"
    ],
    "train_it": [
        "train/code.intoken"
    ],
    "train_ky": [
        "train/code.intoken"
    ],
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_controlflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_dataflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_instatement_files": [
        "../../data/python/train/code.instatement"
    ],
    "train_src_intoken_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_keyword_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_subtoken_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_sub": [
        "train/code.original_subtoken"
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/python/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
02/26/2024 08:26:19 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:19 PM: [ Starting training... ]
02/26/2024 08:26:44 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name python --data_dir ../../data/ --model_dir ../../tmp --model_name code2jdoc --train_src train/code.original_subtoken --train_sub train/code.original_subtoken --train_ky train/code.intoken --train_it train/code.intoken --train_is train/code.instatement --train_df train/dataflow_subtoken_v3.npy --train_cf train/dataflow_subtoken_v3.npy --train_tgt train/javadoc.original --dev_src test/code.original_subtoken --dev_sub test/code.original_subtoken --dev_ky test/code.intoken --dev_it test/code.intoken --dev_is test/code.instatement --dev_df test/dataflow_subtoken_v3.npy --dev_cf test/dataflow_subtoken_v3.npy --dev_tgt test/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 50 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 0 --use_neg_dist True --nlayers 8 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True ]
02/26/2024 08:26:44 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:44 PM: [ Load and process data files ]
02/26/2024 08:26:52 PM: [ Num train examples = 55538 ]
02/26/2024 08:26:52 PM: [ Dataset weights = {1: 1.0} ]
02/26/2024 08:26:54 PM: [ Num dev examples = 18502 ]
02/26/2024 08:26:54 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:54 PM: [ Training model from scratch... ]
02/26/2024 08:26:54 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:26:54 PM: [ Build word dictionary ]
02/26/2024 08:26:58 PM: [ Num words in source = 50000 and target = 30000 ]
02/26/2024 08:27:00 PM: [ Trainable #parameters [encoder-decoder] 58.9M [total] 101M ]
02/26/2024 08:27:00 PM: [ Breakdown of the trainable paramters
+---------------------------------------------------------------+--------------+----------+
| Layer Name                                                    | Output Shape |  Param # |
+---------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight | [50000, 512] | 25600000 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight | [30000, 512] | 15360000 |
| embedder.tgt_pos_embeddings.weight                            |    [52, 512] |    26624 |
| encoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| generator.bias                                                |      [30000] |    30000 |
| copy_attn.linear_in.weight                                    |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                   |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                             |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                               |          [1] |        1 |
+---------------------------------------------------------------+--------------+----------+ ]
02/26/2024 08:27:00 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:27:00 PM: [ Make data loaders ]
02/26/2024 08:27:00 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:27:00 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": false,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "python"
    ],
    "dataset_weights": {
        "1": 1.0
    },
    "dev_cf": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_df": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_is": [
        "test/code.instatement"
    ],
    "dev_it": [
        "test/code.intoken"
    ],
    "dev_ky": [
        "test/code.intoken"
    ],
    "dev_src": [
        "test/code.original_subtoken"
    ],
    "dev_src_controlflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_dataflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_instatement_files": [
        "../../data/python/test/code.instatement"
    ],
    "dev_src_intoken_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_keyword_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_subtoken_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_sub": [
        "test/code.original_subtoken"
    ],
    "dev_tgt": [
        "test/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/python/test/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/code2jdoc.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        0
    ],
    "max_src_len": 150,
    "max_tgt_len": 50,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/code2jdoc.mdl",
    "model_name": "code2jdoc",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 8,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 55538,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/code2jdoc.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_cf": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_df": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_is": [
        "train/code.instatement"
    ],
    "train_it": [
        "train/code.intoken"
    ],
    "train_ky": [
        "train/code.intoken"
    ],
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_controlflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_dataflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_instatement_files": [
        "../../data/python/train/code.instatement"
    ],
    "train_src_intoken_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_keyword_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_subtoken_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_sub": [
        "train/code.original_subtoken"
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/python/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
02/26/2024 08:27:00 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 08:27:00 PM: [ Starting training... ]
02/26/2024 11:51:49 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name python --data_dir ../../data/ --model_dir ../../tmp --model_name code2jdoc --train_src train/code.original_subtoken --train_sub train/code.original_subtoken --train_ky train/code.intoken --train_it train/code.intoken --train_is train/code.instatement --train_df train/dataflow_subtoken_v3.npy --train_cf train/dataflow_subtoken_v3.npy --train_tgt train/javadoc.original --dev_src test/code.original_subtoken --dev_sub test/code.original_subtoken --dev_ky test/code.intoken --dev_it test/code.intoken --dev_is test/code.instatement --dev_df test/dataflow_subtoken_v3.npy --dev_cf test/dataflow_subtoken_v3.npy --dev_tgt test/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 50 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 0 --use_neg_dist True --nlayers 8 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True ]
02/26/2024 11:51:49 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 11:51:49 PM: [ Load and process data files ]
02/26/2024 11:51:55 PM: [ Num train examples = 55538 ]
02/26/2024 11:51:55 PM: [ Dataset weights = {1: 1.0} ]
02/26/2024 11:51:57 PM: [ Num dev examples = 18502 ]
02/26/2024 11:51:57 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 11:51:57 PM: [ Training model from scratch... ]
02/26/2024 11:51:57 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 11:51:57 PM: [ Build word dictionary ]
02/26/2024 11:51:59 PM: [ Num words in source = 50000 and target = 30000 ]
02/26/2024 11:52:00 PM: [ Trainable #parameters [encoder-decoder] 58.9M [total] 101M ]
02/26/2024 11:52:00 PM: [ Breakdown of the trainable paramters
+---------------------------------------------------------------+--------------+----------+
| Layer Name                                                    | Output Shape |  Param # |
+---------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight | [50000, 512] | 25600000 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight | [30000, 512] | 15360000 |
| embedder.tgt_pos_embeddings.weight                            |    [52, 512] |    26624 |
| encoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| generator.bias                                                |      [30000] |    30000 |
| copy_attn.linear_in.weight                                    |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                   |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                             |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                               |          [1] |        1 |
+---------------------------------------------------------------+--------------+----------+ ]
02/26/2024 11:52:00 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 11:52:00 PM: [ Make data loaders ]
02/26/2024 11:52:00 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 11:52:00 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": false,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "python"
    ],
    "dataset_weights": {
        "1": 1.0
    },
    "dev_cf": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_df": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_is": [
        "test/code.instatement"
    ],
    "dev_it": [
        "test/code.intoken"
    ],
    "dev_ky": [
        "test/code.intoken"
    ],
    "dev_src": [
        "test/code.original_subtoken"
    ],
    "dev_src_controlflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_dataflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_instatement_files": [
        "../../data/python/test/code.instatement"
    ],
    "dev_src_intoken_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_keyword_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_subtoken_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_sub": [
        "test/code.original_subtoken"
    ],
    "dev_tgt": [
        "test/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/python/test/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/code2jdoc.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        0
    ],
    "max_src_len": 150,
    "max_tgt_len": 50,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/code2jdoc.mdl",
    "model_name": "code2jdoc",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 8,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 55538,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/code2jdoc.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_cf": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_df": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_is": [
        "train/code.instatement"
    ],
    "train_it": [
        "train/code.intoken"
    ],
    "train_ky": [
        "train/code.intoken"
    ],
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_controlflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_dataflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_instatement_files": [
        "../../data/python/train/code.instatement"
    ],
    "train_src_intoken_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_keyword_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_subtoken_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_sub": [
        "train/code.original_subtoken"
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/python/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
02/26/2024 11:52:00 PM: [ ---------------------------------------------------------------------------------------------------- ]
02/26/2024 11:52:00 PM: [ Starting training... ]
03/01/2024 12:23:12 PM: [ COMMAND: ../../main/train.py --data_workers 5 --dataset_name python --data_dir ../../data/ --model_dir ../../tmp --model_name code2jdoc --train_src train/code.original_subtoken --train_sub train/code.original_subtoken --train_ky train/code.intoken --train_it train/code.intoken --train_is train/code.instatement --train_df train/dataflow_subtoken_v3.npy --train_cf train/dataflow_subtoken_v3.npy --train_tgt train/javadoc.original --dev_src test/code.original_subtoken --dev_sub test/code.original_subtoken --dev_ky test/code.intoken --dev_it test/code.intoken --dev_is test/code.instatement --dev_df test/dataflow_subtoken_v3.npy --dev_cf test/dataflow_subtoken_v3.npy --dev_tgt test/javadoc.original --uncase True --use_src_word True --use_src_char False --use_tgt_word True --use_tgt_char False --max_src_len 150 --max_tgt_len 50 --emsize 512 --fix_embeddings False --src_vocab_size 50000 --tgt_vocab_size 30000 --share_decoder_embeddings True --max_examples -1 --batch_size 32 --test_batch_size 64 --num_epochs 200 --model_type transformer --num_head 8 --d_k 64 --d_v 64 --d_ff 2048 --src_pos_emb False --tgt_pos_emb True --max_relative_pos 0 --use_neg_dist True --nlayers 8 --trans_drop 0.2 --dropout_emb 0.2 --dropout 0.2 --copy_attn True --early_stop 20 --warmup_steps 2000 --optimizer adam --learning_rate 0.0001 --lr_decay 0.99 --valid_metric bleu --checkpoint True ]
03/01/2024 12:23:12 PM: [ ---------------------------------------------------------------------------------------------------- ]
03/01/2024 12:23:12 PM: [ Load and process data files ]
03/01/2024 12:23:20 PM: [ Num train examples = 55538 ]
03/01/2024 12:23:20 PM: [ Dataset weights = {1: 1.0} ]
03/01/2024 12:23:22 PM: [ Num dev examples = 18502 ]
03/01/2024 12:23:22 PM: [ ---------------------------------------------------------------------------------------------------- ]
03/01/2024 12:23:22 PM: [ Training model from scratch... ]
03/01/2024 12:23:22 PM: [ ---------------------------------------------------------------------------------------------------- ]
03/01/2024 12:23:22 PM: [ Build word dictionary ]
03/01/2024 12:23:24 PM: [ Num words in source = 50000 and target = 30000 ]
03/01/2024 12:23:24 PM: [ Trainable #parameters [encoder-decoder] 58.9M [total] 101M ]
03/01/2024 12:23:24 PM: [ Breakdown of the trainable paramters
+---------------------------------------------------------------+--------------+----------+
| Layer Name                                                    | Output Shape |  Param # |
+---------------------------------------------------------------+--------------+----------+
| embedder.src_word_embeddings.make_embedding.emb_luts.0.weight | [50000, 512] | 25600000 |
| embedder.tgt_word_embeddings.make_embedding.emb_luts.0.weight | [30000, 512] | 15360000 |
| embedder.tgt_pos_embeddings.weight                            |    [52, 512] |    26624 |
| encoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| encoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| encoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| encoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| encoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| encoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| encoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| encoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| encoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| encoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.0.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.0.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.0.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.0.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.0.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.0.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.0.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.0.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.0.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.0.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.1.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.1.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.1.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.1.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.1.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.1.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.1.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.1.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.1.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.1.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.2.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.2.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.2.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.2.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.2.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.2.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.2.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.2.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.2.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.2.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.3.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.3.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.3.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.3.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.3.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.3.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.3.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.3.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.3.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.3.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.4.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.4.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.4.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.4.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.4.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.4.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.4.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.4.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.4.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.4.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.5.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.5.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.5.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.5.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.5.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.5.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.5.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.5.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.5.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.5.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.6.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.6.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.6.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.6.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.6.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.6.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.6.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.6.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.6.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.6.feed_forward.layer_norm.bias      |        [512] |      512 |
| decoder.transformer.layer.7.attention.key.weight              |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.key.bias                |        [512] |      512 |
| decoder.transformer.layer.7.attention.query.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.query.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.value.weight            |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.value.bias              |        [512] |      512 |
| decoder.transformer.layer.7.attention.output.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.attention.output.bias             |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.weight                 |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm.bias                   |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.key.weight           |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.key.bias             |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.query.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.query.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.value.weight         |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.value.bias           |        [512] |      512 |
| decoder.transformer.layer.7.context_attn.output.weight        |   [512, 512] |   262144 |
| decoder.transformer.layer.7.context_attn.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.weight               |        [512] |      512 |
| decoder.transformer.layer.7.layer_norm_2.bias                 |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.intermediate.weight  |  [2048, 512] |  1048576 |
| decoder.transformer.layer.7.feed_forward.intermediate.bias    |       [2048] |     2048 |
| decoder.transformer.layer.7.feed_forward.output.weight        |  [512, 2048] |  1048576 |
| decoder.transformer.layer.7.feed_forward.output.bias          |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.weight    |        [512] |      512 |
| decoder.transformer.layer.7.feed_forward.layer_norm.bias      |        [512] |      512 |
| generator.bias                                                |      [30000] |    30000 |
| copy_attn.linear_in.weight                                    |   [512, 512] |   262144 |
| copy_attn.linear_out.weight                                   |  [512, 1024] |   524288 |
| copy_generator.linear_copy.weight                             |     [1, 512] |      512 |
| copy_generator.linear_copy.bias                               |          [1] |        1 |
+---------------------------------------------------------------+--------------+----------+ ]
03/01/2024 12:23:24 PM: [ ---------------------------------------------------------------------------------------------------- ]
03/01/2024 12:23:24 PM: [ Make data loaders ]
03/01/2024 12:23:24 PM: [ ---------------------------------------------------------------------------------------------------- ]
03/01/2024 12:23:24 PM: [ CONFIG:
{
    "attn_type": "general",
    "batch_size": 32,
    "bidirection": true,
    "char_emsize": 16,
    "checkpoint": true,
    "code_tag_type": "subtoken",
    "conditional_decoding": false,
    "copy_attn": true,
    "coverage_attn": false,
    "cuda": false,
    "d_ff": 2048,
    "d_k": 64,
    "d_v": 64,
    "data_dir": "../../data/",
    "data_workers": 5,
    "dataset_name": [
        "python"
    ],
    "dataset_weights": {
        "1": 1.0
    },
    "dev_cf": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_df": [
        "test/dataflow_subtoken_v3.npy"
    ],
    "dev_is": [
        "test/code.instatement"
    ],
    "dev_it": [
        "test/code.intoken"
    ],
    "dev_ky": [
        "test/code.intoken"
    ],
    "dev_src": [
        "test/code.original_subtoken"
    ],
    "dev_src_controlflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_dataflow_files": [
        "../../data/python/test/dataflow_subtoken_v3.npy"
    ],
    "dev_src_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_instatement_files": [
        "../../data/python/test/code.instatement"
    ],
    "dev_src_intoken_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_keyword_files": [
        "../../data/python/test/code.intoken"
    ],
    "dev_src_subtoken_files": [
        "../../data/python/test/code.original_subtoken"
    ],
    "dev_src_tag": null,
    "dev_src_tag_files": [
        null
    ],
    "dev_sub": [
        "test/code.original_subtoken"
    ],
    "dev_tgt": [
        "test/javadoc.original"
    ],
    "dev_tgt_files": [
        "../../data/python/test/javadoc.original"
    ],
    "display_iter": 25,
    "dropout": 0.2,
    "dropout_emb": 0.2,
    "dropout_rnn": 0.2,
    "early_stop": 20,
    "emsize": 512,
    "filter_size": 5,
    "fix_embeddings": false,
    "force_copy": false,
    "grad_clipping": 5.0,
    "layer_wise_attn": false,
    "learning_rate": 0.0001,
    "log_file": "../../tmp/code2jdoc.txt",
    "lr_decay": 0.99,
    "max_characters_per_token": 30,
    "max_examples": -1,
    "max_relative_pos": [
        0
    ],
    "max_src_len": 150,
    "max_tgt_len": 50,
    "model_dir": "../../tmp",
    "model_file": "../../tmp/code2jdoc.mdl",
    "model_name": "code2jdoc",
    "model_type": "transformer",
    "momentum": 0,
    "n_characters": 260,
    "nfilters": 100,
    "nhid": 200,
    "nlayers": 8,
    "num_epochs": 200,
    "num_head": 8,
    "num_train_examples": 55538,
    "only_test": false,
    "optimizer": "adam",
    "parallel": false,
    "pred_file": "../../tmp/code2jdoc.json",
    "pretrained": null,
    "print_copy_info": false,
    "print_one_target": false,
    "random_seed": 1013,
    "reload_decoder_state": null,
    "reuse_copy_attn": false,
    "review_attn": false,
    "rnn_type": "LSTM",
    "share_decoder_embeddings": true,
    "sort_by_len": true,
    "split_decoder": false,
    "src_pos_emb": false,
    "src_vocab_size": 50000,
    "test_batch_size": 64,
    "tgt_pos_emb": true,
    "tgt_vocab_size": 30000,
    "train_cf": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_df": [
        "train/dataflow_subtoken_v3.npy"
    ],
    "train_is": [
        "train/code.instatement"
    ],
    "train_it": [
        "train/code.intoken"
    ],
    "train_ky": [
        "train/code.intoken"
    ],
    "train_src": [
        "train/code.original_subtoken"
    ],
    "train_src_controlflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_dataflow_files": [
        "../../data/python/train/dataflow_subtoken_v3.npy"
    ],
    "train_src_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_instatement_files": [
        "../../data/python/train/code.instatement"
    ],
    "train_src_intoken_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_keyword_files": [
        "../../data/python/train/code.intoken"
    ],
    "train_src_subtoken_files": [
        "../../data/python/train/code.original_subtoken"
    ],
    "train_src_tag": null,
    "train_src_tag_files": [
        null
    ],
    "train_sub": [
        "train/code.original_subtoken"
    ],
    "train_tgt": [
        "train/javadoc.original"
    ],
    "train_tgt_files": [
        "../../data/python/train/javadoc.original"
    ],
    "trans_drop": 0.2,
    "uncase": true,
    "use_all_enc_layers": false,
    "use_code_type": false,
    "use_neg_dist": true,
    "use_src_char": false,
    "use_src_word": true,
    "use_tgt_char": false,
    "use_tgt_word": true,
    "valid_metric": "bleu",
    "warmup_epochs": 0,
    "warmup_steps": 2000,
    "weight_decay": 0
} ]
03/01/2024 12:23:24 PM: [ ---------------------------------------------------------------------------------------------------- ]
03/01/2024 12:23:24 PM: [ Starting training... ]
